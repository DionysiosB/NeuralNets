{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzbLCuZvUktC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\").read().splitlines()"
      ],
      "metadata": {
        "id": "zcG7Ac3xUw8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Min and max word length\n",
        "lengths = [len(w) for w in words]\n",
        "minlength = min(lengths)\n",
        "maxlength = max(lengths)\n",
        "print(f\"{minlength=}, {maxlength=}\")\n",
        "minwords = [w for w in words if len(w) == minlength]\n",
        "maxwords = [w for w in words if len(w) == maxlength]\n",
        "print(f\"MinLength words:{minwords}\")\n",
        "print(f\"MaxLength words:{maxwords}\")"
      ],
      "metadata": {
        "id": "ZYfYmgyRVV0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "charlist = sorted(set(\"\".join(words)))\n",
        "charlist = ['.'] + charlist\n",
        "numfromchar = {ch : k for k,ch in enumerate(charlist)}\n",
        "charfromnum = {k : ch for k,ch in enumerate(charlist)}\n",
        "\n",
        "f = [[0] * len(charlist) for _ in range(len(charlist))]\n",
        "\n",
        "for w in words:\n",
        "    t = '.' + w + '.'\n",
        "    for ch1,ch2 in zip(t, t[1:]):\n",
        "        idx1 = numfromchar[ch1]\n",
        "        idx2 = numfromchar[ch2]\n",
        "        f[idx1][idx2] += 1\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 16));\n",
        "plt.imshow(f, cmap=\"Blues\");\n",
        "for row in range(len(f)):\n",
        "    for col in range(len(f[0])):\n",
        "        label = charfromnum[row] + charfromnum[col]\n",
        "        plt.text(row, col, label, ha=\"center\", va=\"bottom\", color=\"gray\")\n",
        "        plt.text(row, col, f[row][col], ha=\"center\", va=\"top\", color=\"gray\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "nfr-_7uxVt8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Test the model - generate some random words\n",
        "\n",
        "g = []\n",
        "sentinel = 1.0\n",
        "for row in range(len(f)):\n",
        "    rowsum = sum(f[row]) + sentinel * len(f[row])\n",
        "    cur = [(x + sentinel) / rowsum for x in f[row]]\n",
        "    g.append(cur)\n",
        "\n",
        "def generateRandomName():\n",
        "    idx = 0\n",
        "    res = \"\"\n",
        "    while True:\n",
        "        idx = max(idx, 0) #For the initial iteration\n",
        "        cur = np.cumsum(g[idx])\n",
        "        rdn = random.random()\n",
        "        for k in range(len(cur)):\n",
        "            if rdn <= cur[k]:\n",
        "                idx = k\n",
        "                break\n",
        "        if not idx: break\n",
        "        res += charfromnum[idx]\n",
        "\n",
        "    return res\n",
        "\n",
        "for _ in range(10): print(generateRandomName())\n",
        ""
      ],
      "metadata": {
        "id": "-6KNS-BlWXQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def wordnll(word:str) -> float:\n",
        "    t = '.' + word + '.'\n",
        "    sumnll = 0.0\n",
        "    cnt = 0\n",
        "    for ch1,ch2 in zip(t, t[1:]):\n",
        "        idx1 = numfromchar[ch1]\n",
        "        idx2 = numfromchar[ch2]\n",
        "        cnt += 1\n",
        "        sumnll -= np.log(g[idx1][idx2])\n",
        "    return  sumnll / cnt\n",
        "\n",
        "print([wordnll(x) for x in words[:10]])\n",
        "print(wordnll(\"dionysios\"))\n",
        "\n",
        "def allwordsnll(words:list) -> float:\n",
        "    sumnll = 0.0\n",
        "    cnt = 0\n",
        "    for w in words:\n",
        "        t = '.' + w + '.'\n",
        "        for ch1,ch2 in zip(t, t[1:]):\n",
        "            idx1 = numfromchar[ch1]\n",
        "            idx2 = numfromchar[ch2]\n",
        "            cnt += 1\n",
        "            sumnll -= np.log(g[idx1][idx2])\n",
        "    return  sumnll / cnt\n",
        "\n",
        "print(allwordsnll(words))"
      ],
      "metadata": {
        "id": "aVjXt5yYbDzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Neural Network Implementation with PyTorch\n",
        "\n",
        "xs = list()\n",
        "ys = list()\n",
        "nc = len(charlist)\n",
        "\n",
        "for w in words:\n",
        "    t = '.' + w + '.'\n",
        "    for ch1,ch2 in zip(t, t[1:]):\n",
        "        idx1 = numfromchar[ch1]\n",
        "        idx2 = numfromchar[ch2]\n",
        "        xs.append(idx1)\n",
        "        ys.append(idx2)\n",
        "\n",
        "numtrain = len(xs)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "\n",
        "xenc = F.one_hot(xs, num_classes=nc).float()\n",
        "yenc = F.one_hot(ys, num_classes=nc).float()\n",
        "print(xenc.shape, yenc.shape)\n",
        "plt.imshow(xenc[:20]);"
      ],
      "metadata": {
        "id": "acZrGsLxceKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((nc,nc))\n",
        "logits = xenc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)"
      ],
      "metadata": {
        "id": "An0DjZt5faLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27,27), generator=g, requires_grad=True)\n",
        "\n",
        "xenc = F.one_hot(xs, num_classes=nc).float()\n",
        "logits = xenc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "nlls = torch.zeros(5)\n",
        "for k in range(5):\n",
        "    x = xs[k].item()\n",
        "    y = ys[k].item()\n",
        "    nlls[k] = -torch.log(probs[k, y])\n",
        "    print(f\"{k=} nll={nlls[k].item()}\")\n",
        "\n",
        "print(nlls.mean().item())\n",
        "loss = -probs[torch.arange(numtrain), ys].log().mean()\n",
        "print(loss)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jpyqiM7fhNrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1000):\n",
        "    xenc = F.one_hot(xs, num_classes=27).float()\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdims=True)\n",
        "    loss = -probs[torch.arange(numtrain), ys].log().mean()\n",
        "    W.grad = None\n",
        "    if k % 50 == 0: print(loss)\n",
        "    loss.backward()\n",
        "    W.data -= 1 * W.grad"
      ],
      "metadata": {
        "id": "0wasPtjxijOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DlR_b1Ulincg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}